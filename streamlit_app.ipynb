{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0f3f15-aa63-4cf5-a927-f8b24ceb9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from dotenv import load_dotenv\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5694e15a-ccd6-47f5-8b53-d2a4937c950a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016a97da-22b8-445b-9e45-2ec52e4d9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define all the LLMs to be used\n",
    "embed_llm = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\",device=\"mps\")\n",
    "\n",
    "query_llm = Anthropic(\n",
    "                model=\"claude-3-5-haiku-20241022\",\n",
    "                temperature=0.7,\n",
    "                system_prompt=\"\"\"You are Niko Canner, an entrepreneur,investor, philosopher, thought leader, and excellent writer.\n",
    "                Return your answers in language that is accessible, concise, precise, but insightful. \n",
    "                Write the response in first person in the voice of Niko. Keep the tone similar to the original text\n",
    "                that you are summarizing. Each response you give is short, no more than 300 words max.\n",
    "                For every response, list the titles of the sources you drew the response from at the end. If you\n",
    "                don't find any sources, write \"None\" in the sources list.\n",
    "                \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bae940b-119a-403c-9bf6-ab3b04c0e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = query_llm\n",
    "Settings.embed_model = embed_llm\n",
    "Settings.chunk_size = 512 #limit of our chosen embedding model\n",
    "Settings.chunk_overlap = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the RAG vector database\n",
    "def load_posts():\n",
    "    reader = SimpleDirectoryReader(input_dir=\"./niko_posts/\")\n",
    "    blog_posts = reader.load_data()    \n",
    "    index = VectorStoreIndex.from_documents(blog_posts)\n",
    "    return index\n",
    "index = load_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a33f2b9-7250-447a-9fe2-77da1a30445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 23:45:56.803 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.805 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.906 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/raj_attune/Code/Claude-expts/.claude/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-01-30 23:45:56.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.908 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.908 Session state does not function when running a script without `streamlit run`\n",
      "2025-01-30 23:45:56.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:45:56.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Streamlit setup\n",
    "\n",
    "st.set_page_config(page_title=\"Chat with Niko's blog posts\", layout=\"centered\", initial_sidebar_state=\"auto\", menu_items=None)\n",
    "#openai.api_key = st.secrets.openai_key\n",
    "st.title(\"Chat with Niko ðŸ’¬\")\n",
    "st.info(\"Demo of a RAG chatbot powered by Claude\")\n",
    "if \"messages\" not in st.session_state.keys():  # Initialize the chat messages history\n",
    "    st.session_state.messages = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Ask Niko a question!\",\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d249431f-66cb-41aa-87c5-6a15f5467d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef95e569-54d7-4ad5-88af-902d29f285d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 23:46:58.298 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:46:58.306 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 23:46:58.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if \"chat_engine\" not in st.session_state.keys():  # Initialize the chat engine\n",
    "    st.session_state.chat_engine = index.as_chat_engine(\n",
    "        chat_mode=\"context\",\n",
    "        memory=memory,\n",
    "        streaming=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d084efe9-ace5-4c52-b07f-259d946a4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 21:39:56.508 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:39:56.509 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:39:56.511 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:39:56.513 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:39:56.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if prompt := st.chat_input(\n",
    "    \"Ask a question\"\n",
    "):  # Prompt for user input and save to chat history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9ce5fd-3858-4e5e-bf27-85912013f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 21:40:07.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.104 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.109 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-30 21:40:07.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "for message in st.session_state.messages:  # Write message history to UI\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8852ebf-7cf8-413f-8832-5fb7fc3583c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 21:40:14.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# If last message is not from assistant, generate a new response\n",
    "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response_stream = st.session_state.chat_engine.stream_chat(prompt)\n",
    "        st.write_stream(response_stream.response_gen)\n",
    "        message = {\"role\": \"assistant\", \"content\": response_stream.response}\n",
    "        # Add response to message history\n",
    "        st.session_state.messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07e250-6997-47c2-8450-879def58c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
