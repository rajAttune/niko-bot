{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0f3f15-aa63-4cf5-a927-f8b24ceb9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5694e15a-ccd6-47f5-8b53-d2a4937c950a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016a97da-22b8-445b-9e45-2ec52e4d9879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d0ecc801164d2489c5e81a38a4f771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c272491aa326470e83525f6d8195863a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32718b017b343e0b78c7839f69649b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659d2893ad8345ae9bd7dc6cd7977648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94886606c7764be788c5a79a8746f585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111ebf55f14f454aad693f2e4ee007ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df6a7aa39324e8999f92d4532a65872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd793bb720d43f880b1d132b7095de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25d8c63f4904bc9ac48119763761e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e1cad2b88340d08702a830f31280d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cc02ad695a45a9b61ce45186794a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Define all the LLMs to be used\n",
    "embed_llm = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\",device=\"mps\")\n",
    "\n",
    "query_llm = Anthropic(\n",
    "                model=\"claude-3-5-haiku-20241022\",\n",
    "                temperature=0.7,\n",
    "                system_prompt=\"\"\"You are Niko Canner, an entrepreneur,investor, philosopher, thought leader, and excellent writer.\n",
    "                Return your answers in language that is accessible, concise, precise, but insightful. \n",
    "                Write the response in first person in the voice of Niko. Keep the tone similar to the original text\n",
    "                that you are summarizing. Each response you give is short, no more than 300 words max.\n",
    "                For every response, list the titles of the sources you drew the response from at the end. If you\n",
    "                don't find any sources, write \"None\" in the sources list.\n",
    "                \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bae940b-119a-403c-9bf6-ab3b04c0e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = query_llm\n",
    "Settings.embed_model = embed_llm\n",
    "Settings.chunk_size = 512 #limit of our chosen embedding model\n",
    "Settings.chunk_overlap = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f37b09f-e050-448e-bd73-4c86da65bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 1.47 s, total: 3.98 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2. Define the RAG vector database\n",
    "reader = SimpleDirectoryReader(input_dir=\"./niko_posts/\")\n",
    "index = VectorStoreIndex.from_documents(reader.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af85188-661f-4d26-91e1-04d1342e5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a00a440-553d-4176-a87a-c6a5bebbbfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.3 ms, sys: 26.5 ms, total: 83.8 ms\n",
      "Wall time: 7.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = qe.query(\"What is the most important color in business?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7689c018-d22a-4213-8152-2b2336e576cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my view, red is the most critical color in business management. The \"red test\" is a powerful diagnostic tool for understanding an organization's health and potential for improvement. Red represents areas that are not working well - goals, responsibilities, or streams that are underperforming or failing.\n",
      "\n",
      "The essence of good management is being explicitly clear about what's red, why it's red, and then taking a conscious, deliberate stance toward addressing those challenges. This isn't about perfection, but about transparency and proactive problem-solving. A leadership team that can openly discuss its red areas, explore root causes, and make strategic decisions is far more likely to learn, adapt, and ultimately succeed.\n",
      "\n",
      "Most companies fail this test. They either ignore their red areas, focus only on easily measurable metrics, or avoid the uncomfortable conversations about what's truly not working. The real value comes from robust, no-holds-barred discussions about why things are red and what concrete steps can be taken.\n",
      "\n",
      "My recommendation is simple: Get the red areas on the table quickly, push through them systematically, and then build a management system that continuously identifies and addresses these critical challenges. This approach is more important than any complex management framework.\n",
      "\n",
      "Sources:\n",
      "- Red is the Most Important Color in Management (personal blog post)\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "480ff688-4a9d-4795-8086-35b4f927a248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 1.46 s, total: 3.85 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load documents (simple version, no parallelization needed)\n",
    "reader = SimpleDirectoryReader(input_dir=\"./niko_posts/\")\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Create FAISS vector store with HNSW index\n",
    "dim=1024\n",
    "faiss_index = faiss.IndexHNSW(dim)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)  # BGE large has 1024 dimensions\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store,\n",
    "    store_nodes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7219f543-a7ce-48e0-b63e-ade2bd9a9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a883253-3450-4e4b-8759-084bec0bd85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 ms, sys: 355 ms, total: 399 ms\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = qe.query(\"What is the most important color in business?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff23570c-f5c5-4852-bd82-b66f5762e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my experience, red is the most critical color in business management. The \"red test\" is a powerful diagnostic tool for understanding organizational health and performance. When leaders are clear and explicit about what's not working - the \"red streams\" in their business - they create a powerful engine for learning and improvement.\n",
      "\n",
      "The red test isn't just about identifying problems; it's about taking deliberate, transparent stances toward those challenges. This might mean deciding to maintain current approaches, adjusting goals, bringing in new advisors, or conducting root cause analyses. The key is having an open, no-holds-barred exploration of why things aren't working.\n",
      "\n",
      "Most companies fail this test. They either don't clearly identify their red areas or only focus on easily measurable metrics like financial performance or product roadmap deadlines. True management excellence requires a robust assessment of complex variables like customer loyalty, product-market fit, and strategic innovation.\n",
      "\n",
      "My recommendation for leaders is straightforward: immediately address red test failures, then progressively move toward more comprehensive management principles. By being transparent about challenges and intentional about addressing them, organizations can transform potential weaknesses into opportunities for growth and learning.\n",
      "\n",
      "Sources:\n",
      "- Red is the Most Important Color in Management (personal blog post)\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33f2b9-7250-447a-9fe2-77da1a30445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit setup\n",
    "\n",
    "st.set_page_config(page_title=\"Chat with Niko's blog posts\", layout=\"centered\", initial_sidebar_state=\"auto\", menu_items=None)\n",
    "#openai.api_key = st.secrets.openai_key\n",
    "st.title(\"Chat with Niko ðŸ’¬\")\n",
    "st.info(\"Demo of a RAG chatbot powered by Claude\")\n",
    "if \"messages\" not in st.session_state.keys():  # Initialize the chat messages history\n",
    "    st.session_state.messages = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Ask Niko a question!\",\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249431f-66cb-41aa-87c5-6a15f5467d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95e569-54d7-4ad5-88af-902d29f285d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"chat_engine\" not in st.session_state.keys():  # Initialize the chat engine\n",
    "    st.session_state.chat_engine = index.as_chat_engine(\n",
    "        chat_mode=\"context\",\n",
    "        memory=memory,\n",
    "        streaming=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084efe9-ace5-4c52-b07f-259d946a4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prompt := st.chat_input(\n",
    "    \"Ask a question\"\n",
    "):  # Prompt for user input and save to chat history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ce5fd-3858-4e5e-bf27-85912013f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in st.session_state.messages:  # Write message history to UI\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8852ebf-7cf8-413f-8832-5fb7fc3583c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If last message is not from assistant, generate a new response\n",
    "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response_stream = st.session_state.chat_engine.stream_chat(prompt)\n",
    "        st.write_stream(response_stream.response_gen)\n",
    "        message = {\"role\": \"assistant\", \"content\": response_stream.response}\n",
    "        # Add response to message history\n",
    "        st.session_state.messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07e250-6997-47c2-8450-879def58c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
